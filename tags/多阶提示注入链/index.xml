<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>多阶提示注入链 on cmdragon's Blog</title><link>https://blog.cmdragon.cn/tags/%E5%A4%9A%E9%98%B6%E6%8F%90%E7%A4%BA%E6%B3%A8%E5%85%A5%E9%93%BE/</link><description>Recent content in 多阶提示注入链 on cmdragon's Blog</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 09 Sep 2025 07:05:15 +0800</lastBuildDate><atom:link href="https://blog.cmdragon.cn/tags/%E5%A4%9A%E9%98%B6%E6%8F%90%E7%A4%BA%E6%B3%A8%E5%85%A5%E9%93%BE/index.xml" rel="self" type="application/rss+xml"/><item><title>DeepSeek大模型核心提示词泄露揭示AI安全边界漏洞</title><link>https://blog.cmdragon.cn/posts/7c447c30695a9e53c1d8abc9a6ddac54/</link><pubDate>Tue, 09 Sep 2025 07:05:15 +0800</pubDate><guid>https://blog.cmdragon.cn/posts/7c447c30695a9e53c1d8abc9a6ddac54/</guid><description>国际安全研究人员成功绕过DeepSeek V3大语言模型的安全防护机制，完整提取其核心系统提示词，揭示了大模型底层安全架构的脆弱性。泄露的提示词包含超过1500字符的行为规范，涵盖伦理准则、内容审查和任务处理三大模块。研究人员采用创新的“多阶提示注入链”技术穿透模型防护，引发对当前RLHF防护范式的质疑。DeepSeek团队迅速启动应急响应，包括动态指令混淆机制和对抗性训练增强模块。事件凸显生成式AI安全的深层次矛盾，如透明度悖论和动态攻防困境，并预测未来大模型安全加固产业将快速增长。</description></item></channel></rss>